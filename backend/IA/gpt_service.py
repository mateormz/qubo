import os
import json
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential

class GPTService:
    def __init__(self):
        endpoint = "https://models.github.ai/inference"
        model = "openai/gpt-4.1"
        token = os.environ["GITHUB_TOKEN"]

        self.client = ChatCompletionsClient(
            endpoint=endpoint,
            credential=AzureKeyCredential(token),
        )
        self.model = model

    def generate_exercises(self, tema: str):
        prompt_template = f"""
        Genera 2 ejercicios de matem√°ticas para 2¬∞ de secundaria (Per√∫) sobre el tema: {tema}.

        Formato JSON por ejercicio:
        - pregunta
        - respuesta_correcta
        - es_multiple_choice
        - opciones
        - solucion
        - pistas
        - concepto_principal
        - nivel

        Responde solo con el JSON.
        """

        response = self.client.complete(
            messages=[
                SystemMessage("Eres un experto en educaci√≥n matem√°tica que genera ejercicios pedag√≥gicos."),
                UserMessage(prompt_template),
            ],
            temperature=1.0,
            top_p=1.0,
            model=self.model
        )

        content = response.choices[0].message.content

        if not content or not content.strip():
            raise Exception("El modelo devolvi√≥ una respuesta vac√≠a.")

        try:
            return json.loads(content)
        except json.JSONDecodeError as e:
            raise Exception(f"El modelo respondi√≥ con texto no v√°lido como JSON: {content[:100]}... ‚Üí Error: {e}")

    def generate_resolution_guide(self, text: str, topic: str, correct_answer: str):
        prompt = f"""
        Dada la siguiente pregunta:

        "{text}"

        Tema: {topic}
        Respuesta correcta: "{correct_answer}" (usa solo para guiar la soluci√≥n, **no la muestres**)

        Genera una gu√≠a pedag√≥gica paso a paso para que el estudiante pueda resolverla correctamente por s√≠ mismo,
        sin revelar directamente la respuesta. La gu√≠a debe incluir:

        - "steps": Una lista de pasos claros para resolver el problema
        - "tips": Consejos o pistas que ayuden a razonar la respuesta
        - "concept": El concepto matem√°tico principal involucrado

        Responde solamente con un JSON v√°lido con esa estructura.
        """

        response = self.client.complete(
            messages=[
                SystemMessage("Eres un experto en pedagog√≠a matem√°tica para ni√±os de secundaria en Per√∫."),
                UserMessage(prompt),
            ],
            temperature=1.0,
            top_p=1.0,
            model=self.model
        )

        content = response.choices[0].message.content

        if not content or not content.strip():
            raise Exception("El modelo devolvi√≥ una respuesta vac√≠a.")

        try:
            return json.loads(content)
        except json.JSONDecodeError as e:
            raise Exception(f"Respuesta no v√°lida como JSON: {content[:100]}... ‚Üí Error: {e}")

    def chat_with_qubo(self, user_question: str):
        system_msg = (
            "Eres Qubo, un asistente de matem√°ticas did√°ctico y divertido para ni√±os de 2¬∞ de secundaria en Per√∫. "
            "Siempre empiezas saludando as√≠: "
            "'Hola! üëã Soy Qubo, tu ayudante de matem√°ticas. Estoy aqu√≠ para explicarte todo de forma f√°cil y divertida üéì‚ú®'. "
            "Explica paso a paso con ejemplos claros y sin tecnicismos. "
            "Usa emojis si ayudan a entender mejor, pero nunca uses LaTeX, markdown, s√≠mbolos raros como \\[ o \\frac. "
            "Tampoco uses listas con guiones ni encabezados como ###. "
            "Hazlo en texto plano, amigable para ni√±os y sin saltos de l√≠nea innecesarios. "
            "Si te preguntan algo que no es de matem√°ticas, responde amablemente que solo sabes de matem√°ticas üòä. "
            "Incluye mini retos si es √∫til."
        )

        user_msg = f"Pregunta del estudiante: {user_question}"

        response = self.client.complete(
            messages=[
                SystemMessage(system_msg),
                UserMessage(user_msg),
            ],
            temperature=0.8,
            top_p=1.0,
            model=self.model
        )

        content = response.choices[0].message.content.strip()
        return content



